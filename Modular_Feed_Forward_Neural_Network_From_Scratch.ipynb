{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yYF8PinHHIwO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(x, type, derivative=False):\n",
        "\n",
        "  if type == 'sigmoid':\n",
        "    if derivative:\n",
        "      sig = 1 / (1 + np.exp(-x))\n",
        "      return sig * (1 - sig)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  elif type == 'tanh':\n",
        "      if derivative:\n",
        "        tanh = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "        return 1 - tanh**2\n",
        "      return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "  elif type == 'ReLU':\n",
        "   if derivative:\n",
        "    return np.where(x > 0, 1, 0)\n",
        "   return np.maximum(0, x)"
      ],
      "metadata": {
        "id": "Wp_qiyB5Hh0W"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)"
      ],
      "metadata": {
        "id": "MnfK3ozFZMKC"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neural_Network():\n",
        "\n",
        "\n",
        "  def __init__(self,input_nodes,layers,output_nodes):\n",
        "    self.input_nodes = input_nodes  #dimension of the input vector\n",
        "    self.layers = layers   #number of layers that we want in netork\n",
        "    self.output_nodes = output_nodes  #number of output classes\n",
        "\n",
        "    #convert to small_named variables for comfort\n",
        "    self.n = self.input_nodes\n",
        "    self.L = self.layers\n",
        "    self.k = self.output_nodes\n",
        "\n",
        "    self.W = []  # W will be a list of matrices of size nxn --> n = dimension of input vector\n",
        "    self.B = []  # B will be a list of matrices of size 1xn\n",
        "\n",
        "    #weights & biases initialisation for layers 1 to L-1\n",
        "    for i in range(0, self.L-1):\n",
        "        W_i = np.random.rand(self.n, self.n)/np.sqrt(self.n) # creating nxn matrix\n",
        "        B_i = np.random.rand(1, self.n)  # creating 1xn matrix\n",
        "        self.W.append(W_i)\n",
        "        self.B.append(B_i)\n",
        "\n",
        "    #weights & biases initialisation for last layer\n",
        "    W_i = np.random.rand(self.n,self.k)/np.sqrt(self.n) # creating nxk matrix\n",
        "    B_i = np.random.rand(1,self.k) # creating 1xk matrix\n",
        "    self.W.append(W_i)\n",
        "    self.B.append(B_i)\n",
        "\n",
        "  def forward(self,X):\n",
        "    Y_hat = []\n",
        "    # Initializing lists A and H depending on the number of layers\n",
        "    A = [[] for _ in range(self.layers)]\n",
        "    H = [[] for _ in range(self.layers)]\n",
        "\n",
        "    for x in X:\n",
        "\n",
        "\n",
        "      #input layer\n",
        "      a0 = np.dot(self.W[0],x.T)  + self.B[0].T   #a1 = W1.x + b1\n",
        "      A[0].append(a0)\n",
        "      h0 = activation(a0,type='sigmoid')  #h1 = activation(a1)\n",
        "      H[0].append(h0)\n",
        "\n",
        "      #middle layers\n",
        "      for i in range(1,self.L-1):\n",
        "          # Accessing the value in H[i-1] corresponding to the current x\n",
        "          h_prev = H[i - 1][-1]  # Getting the last element added to H[i-1]\n",
        "          a = np.dot(self.W[i], h_prev) + self.B[i].T  # a = Wi.h(i-1) + Bi\n",
        "          A[i].append(a)\n",
        "          h = activation(a, type='sigmoid')\n",
        "          H[i].append(h)\n",
        "\n",
        "      #output layer\n",
        "      a_L = np.dot(self.W[self.L-1].T,H[self.L-2][-1]) + self.B[self.L-1].T\n",
        "      A[self.L-1].append(a_L)\n",
        "      y_hat = softmax(a_L)\n",
        "      Y_hat.append(y_hat)\n",
        "\n",
        "    return Y_hat, A, H    #each y_hat is a kx1 matrix\n",
        "\n",
        "\n",
        "\n",
        "  def backward(self,X,Y,lr,max_iter):\n",
        "    errors = []\n",
        "\n",
        "    for i in range(max_iter):\n",
        "      print(f\"Iteration: {i}\")\n",
        "      dW = []\n",
        "      dB = []\n",
        "      dA = [[] for _ in range(self.layers)]\n",
        "      dH = [[] for _ in range(self.layers)]\n",
        "\n",
        "      for i in range(0, self.L-1):\n",
        "        dW_i = np.zeros((self.n, self.n))  # creating nxn matrix\n",
        "        dB_i = np.zeros((1, self.n))  # creating 1xn matrix\n",
        "        dW.append(dW_i)\n",
        "        dB.append(dB_i)\n",
        "\n",
        "      dW_i = np.zeros((self.n, self.k))  # creating nxk matrix for last layer\n",
        "      dB_i = np.zeros((1, self.k))  # creating 1xk matrix for last layer\n",
        "      dW.append(dW_i)\n",
        "      dB.append(dB_i)\n",
        "\n",
        "      Y_hat, A, H  = self.forward(X)\n",
        "\n",
        "      for x, y, y_hat in zip(X, Y, Y_hat):\n",
        "\n",
        "        #backpropagating through output layer\n",
        "        grad_A_L_minus_1 = (y_hat - y)\n",
        "        dA[self.L-1].append(grad_A_L_minus_1)\n",
        "\n",
        "        #backpropagating through middle layers\n",
        "        for j in range(self.L-1, 0, -1):\n",
        "          # dw = np.dot(dA[j][-1], H[j-1][-1].T)\n",
        "          # dw = np.dot(dA[j][-1], H[j-1][-1])\n",
        "          dw = np.dot(H[j-1][-1],dA[j][-1].T)\n",
        "          dW[j] += dw\n",
        "          dB[j] += dA[j][-1].T\n",
        "          grad_H_j_minus_1 = np.dot(self.W[j], dA[j][-1])\n",
        "          dH[j-1].append(grad_H_j_minus_1)\n",
        "          grad_A_j_minus_1 = grad_H_j_minus_1 * activation(A[j-1][-1], type='sigmoid', derivative=True)\n",
        "          dA[j-1].append(grad_A_j_minus_1)\n",
        "\n",
        "        #backpropagating through input layer\n",
        "        dw = np.dot(grad_A_j_minus_1, x)\n",
        "        dW[0] += dw\n",
        "        dB[0] += grad_A_j_minus_1.T\n",
        "\n",
        "      #updating the weights and biases\n",
        "      for j in range(self.L):\n",
        "        self.W[j] -= lr * dW[j]\n",
        "        self.B[j] -= lr * dB[j]\n",
        "\n",
        "\n",
        "      # Calculating error after each epoch\n",
        "      Y = np.array(Y)\n",
        "      Y_hat = np.array(Y_hat)\n",
        "      loss = -Y * np.log(Y_hat)\n",
        "      mean_loss = np.mean(loss)\n",
        "      errors.append(mean_loss)\n",
        "      print(\"Mean loss:\", mean_loss)\n",
        "\n",
        "    # Plotting errors vs epoch\n",
        "    plt.plot(errors)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Loss')\n",
        "    plt.title('Training Loss over Epochs')\n",
        "    plt.show()\n",
        "\n",
        "    return self.W,self.B\n",
        "\n"
      ],
      "metadata": {
        "id": "3tmWUGsi0xba"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Neural_Network(5, 3, 4)"
      ],
      "metadata": {
        "id": "7v48UQnCeWNk"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking dimensions for verification\n",
        "for w in model.W:\n",
        "  print(w.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFZfkZSCjztA",
        "outputId": "256eae90-0262-437c-a4f9-ead586d95a60"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5)\n",
            "(5, 5)\n",
            "(5, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in model.B:\n",
        "  print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "015VgiOAkIr9",
        "outputId": "f4ff0270-ea7f-4292-cba1-5617eda5e497"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the dimensions as per our data\n",
        "m = 10  # number of data points\n",
        "n = 5   # dimension of input vectors\n",
        "k = 4   # dimension of output vectors\n",
        "\n",
        "# Preparing X list with random values X = input data\n",
        "X = [np.random.rand(1, n) for _ in range(m)]\n",
        "\n",
        "# Preparing Y list with one-hot encoded vectors\n",
        "Y = []\n",
        "for _ in range(m):\n",
        "    y = np.zeros((k, 1))\n",
        "    index = np.random.randint(0, k)\n",
        "    y[index, 0] = 1\n",
        "    Y.append(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "FUUOVB7rZuqM"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the dimensions\n",
        "for x in X:\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pk1VhoRfFgD",
        "outputId": "b29ac801-c893-47ed-a7ac-40a2a3139316"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n",
            "(1, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for y in Y:\n",
        "  print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJi5ZVovfKNi",
        "outputId": "09ae348a-2f66-44fa-e0d4-f1bc6d71aeaf"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n",
            "(4, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing X and Y for verification\n",
        "print(\"X:\")\n",
        "for x in X:\n",
        "    print(x)\n",
        "\n",
        "print(\"\\nY:\")\n",
        "for y in Y:\n",
        "    print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW-LRB5_Z1Jt",
        "outputId": "86eaa910-2d7c-4fce-9298-a5e9114e3886"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            "[[0.77742541 0.22656042 0.75174604 0.54124795 0.18545851]]\n",
            "[[0.41946468 0.25111953 0.81355829 0.05373892 0.99555771]]\n",
            "[[0.45951869 0.3735928  0.50302072 0.0084996  0.35316853]]\n",
            "[[0.14711328 0.84923127 0.4530475  0.36127415 0.47123622]]\n",
            "[[0.21409702 0.95470554 0.86450057 0.22222517 0.1415354 ]]\n",
            "[[0.06821006 0.26553074 0.06125729 0.43607975 0.14371319]]\n",
            "[[0.46070617 0.16399499 0.92993688 0.79817366 0.79276389]]\n",
            "[[0.1934771  0.79005909 0.62347408 0.52069288 0.96781564]]\n",
            "[[0.34679969 0.91612992 0.57781101 0.67089412 0.59010726]]\n",
            "[[0.96473718 0.67840057 0.00373979 0.047742   0.59871047]]\n",
            "\n",
            "Y:\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred, A1, H1 = model.forward(X)\n",
        "print(\"Y_pred:\")\n",
        "for y_pred in Y_pred:\n",
        "    print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb77raLibNJu",
        "outputId": "2019f91c-2049-4437-e4c6-6f2708807d28"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred:\n",
            "[[0.24506813]\n",
            " [0.09575443]\n",
            " [0.28157939]\n",
            " [0.37759805]]\n",
            "[[0.24505002]\n",
            " [0.09573774]\n",
            " [0.28163207]\n",
            " [0.37758018]]\n",
            "[[0.24496917]\n",
            " [0.09618438]\n",
            " [0.28117821]\n",
            " [0.37766824]]\n",
            "[[0.2450915 ]\n",
            " [0.09570403]\n",
            " [0.28161892]\n",
            " [0.37758556]]\n",
            "[[0.24512176]\n",
            " [0.09566178]\n",
            " [0.2816111 ]\n",
            " [0.37760536]]\n",
            "[[0.24485446]\n",
            " [0.09655812]\n",
            " [0.28091818]\n",
            " [0.37766923]]\n",
            "[[0.24512702]\n",
            " [0.09537972]\n",
            " [0.28199168]\n",
            " [0.37750158]]\n",
            "[[0.24517043]\n",
            " [0.09530056]\n",
            " [0.28202091]\n",
            " [0.3775081 ]]\n",
            "[[0.24519312]\n",
            " [0.09527731]\n",
            " [0.28201067]\n",
            " [0.3775189 ]]\n",
            "[[0.24508189]\n",
            " [0.0958205 ]\n",
            " [0.28145246]\n",
            " [0.37764516]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Y and Y_hat from lists to numpy arrays\n",
        "Y = np.array(Y)\n",
        "Y_hat = np.array(Y_pred)\n",
        "\n",
        "# Computing the loss using -Y * log(Y_hat)\n",
        "loss = -Y * np.log(Y_hat)\n",
        "\n",
        "# Calculating the mean loss\n",
        "mean_loss = np.mean(loss)\n",
        "\n",
        "print(\"Mean loss:\", mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhigLEUB8omB",
        "outputId": "defc05b2-7975-48dc-9d57-a8ad15d778f6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss: 0.33906898048190265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for y_pred in Y_pred:\n",
        "  print(np.sum(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVM5Et2tlrDW",
        "outputId": "9c99d624-d795-47a4-d5a8-ab98279ec75f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "1.0\n",
            "0.9999999999999999\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "max_iter = 100\n",
        "model.backward(X,Y,lr,max_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAoAG8wQ3q3m",
        "outputId": "57325e89-1883-4be4-fa00-ad70504c833d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\n",
            "Mean loss: 0.33906898048190265\n",
            "Iteration: 1\n",
            "Mean loss: 0.32820288887477117\n",
            "Iteration: 2\n",
            "Mean loss: 0.31978048325751196\n",
            "Iteration: 3\n",
            "Mean loss: 0.3133260064433266\n",
            "Iteration: 4\n",
            "Mean loss: 0.3084171652139508\n",
            "Iteration: 5\n",
            "Mean loss: 0.30469864007510494\n",
            "Iteration: 6\n",
            "Mean loss: 0.3018836174517437\n",
            "Iteration: 7\n",
            "Mean loss: 0.29974769972745774\n",
            "Iteration: 8\n",
            "Mean loss: 0.2981192824941245\n",
            "Iteration: 9\n",
            "Mean loss: 0.296869230690893\n",
            "Iteration: 10\n",
            "Mean loss: 0.295901414054131\n",
            "Iteration: 11\n",
            "Mean loss: 0.29514474694417797\n",
            "Iteration: 12\n",
            "Mean loss: 0.29454683988796504\n",
            "Iteration: 13\n",
            "Mean loss: 0.29406910881637294\n",
            "Iteration: 14\n",
            "Mean loss: 0.2936830935737989\n",
            "Iteration: 15\n",
            "Mean loss: 0.29336772966753466\n",
            "Iteration: 16\n",
            "Mean loss: 0.29310734744190986\n",
            "Iteration: 17\n",
            "Mean loss: 0.29289021459280223\n",
            "Iteration: 18\n",
            "Mean loss: 0.2927074787228781\n",
            "Iteration: 19\n",
            "Mean loss: 0.2925524015921814\n",
            "Iteration: 20\n",
            "Mean loss: 0.29241980470698403\n",
            "Iteration: 21\n",
            "Mean loss: 0.29230566741679714\n",
            "Iteration: 22\n",
            "Mean loss: 0.29220683482850496\n",
            "Iteration: 23\n",
            "Mean loss: 0.2921208047423698\n",
            "Iteration: 24\n",
            "Mean loss: 0.2920455714818049\n",
            "Iteration: 25\n",
            "Mean loss: 0.2919795107532496\n",
            "Iteration: 26\n",
            "Mean loss: 0.2919212941753351\n",
            "Iteration: 27\n",
            "Mean loss: 0.29186982534108086\n",
            "Iteration: 28\n",
            "Mean loss: 0.2918241915805139\n",
            "Iteration: 29\n",
            "Mean loss: 0.29178362723470735\n",
            "Iteration: 30\n",
            "Mean loss: 0.2917474854244606\n",
            "Iteration: 31\n",
            "Mean loss: 0.29171521613324003\n",
            "Iteration: 32\n",
            "Mean loss: 0.29168634902149126\n",
            "Iteration: 33\n",
            "Mean loss: 0.2916604798171033\n",
            "Iteration: 34\n",
            "Mean loss: 0.2916372594337445\n",
            "Iteration: 35\n",
            "Mean loss: 0.2916163851898555\n",
            "Iteration: 36\n",
            "Mean loss: 0.29159759366098\n",
            "Iteration: 37\n",
            "Mean loss: 0.291580654814354\n",
            "Iteration: 38\n",
            "Mean loss: 0.2915653671596711\n",
            "Iteration: 39\n",
            "Mean loss: 0.291551553712509\n",
            "Iteration: 40\n",
            "Mean loss: 0.29153905861329554\n",
            "Iteration: 41\n",
            "Mean loss: 0.2915277442793648\n",
            "Iteration: 42\n",
            "Mean loss: 0.29151748899379293\n",
            "Iteration: 43\n",
            "Mean loss: 0.2915081848545781\n",
            "Iteration: 44\n",
            "Mean loss: 0.2914997360229824\n",
            "Iteration: 45\n",
            "Mean loss: 0.29149205722166677\n",
            "Iteration: 46\n",
            "Mean loss: 0.29148507244248256\n",
            "Iteration: 47\n",
            "Mean loss: 0.2914787138310625\n",
            "Iteration: 48\n",
            "Mean loss: 0.2914729207211419\n",
            "Iteration: 49\n",
            "Mean loss: 0.2914676387961812\n",
            "Iteration: 50\n",
            "Mean loss: 0.29146281935960683\n",
            "Iteration: 51\n",
            "Mean loss: 0.2914584186980364\n",
            "Iteration: 52\n",
            "Mean loss: 0.2914543975243457\n",
            "Iteration: 53\n",
            "Mean loss: 0.29145072048948867\n",
            "Iteration: 54\n",
            "Mean loss: 0.291447355753681\n",
            "Iteration: 55\n",
            "Mean loss: 0.29144427460896805\n",
            "Iteration: 56\n",
            "Mean loss: 0.2914414511463782\n",
            "Iteration: 57\n",
            "Mean loss: 0.29143886196185165\n",
            "Iteration: 58\n",
            "Mean loss: 0.2914364858959647\n",
            "Iteration: 59\n",
            "Mean loss: 0.2914343038031727\n",
            "Iteration: 60\n",
            "Mean loss: 0.2914322983468882\n",
            "Iteration: 61\n",
            "Mean loss: 0.2914304538172158\n",
            "Iteration: 62\n",
            "Mean loss: 0.2914287559685929\n",
            "Iteration: 63\n",
            "Mean loss: 0.29142719187495414\n",
            "Iteration: 64\n",
            "Mean loss: 0.29142574980034813\n",
            "Iteration: 65\n",
            "Mean loss: 0.2914244190832047\n",
            "Iteration: 66\n",
            "Mean loss: 0.29142319003268186\n",
            "Iteration: 67\n",
            "Mean loss: 0.2914220538357175\n",
            "Iteration: 68\n",
            "Mean loss: 0.2914210024735862\n",
            "Iteration: 69\n",
            "Mean loss: 0.2914200286469047\n",
            "Iteration: 70\n",
            "Mean loss: 0.2914191257081614\n",
            "Iteration: 71\n",
            "Mean loss: 0.29141828760095423\n",
            "Iteration: 72\n",
            "Mean loss: 0.29141750880521694\n",
            "Iteration: 73\n",
            "Mean loss: 0.2914167842878017\n",
            "Iteration: 74\n",
            "Mean loss: 0.29141610945785407\n",
            "Iteration: 75\n",
            "Mean loss: 0.29141548012648383\n",
            "Iteration: 76\n",
            "Mean loss: 0.29141489247029173\n",
            "Iteration: 77\n",
            "Mean loss: 0.29141434299835656\n",
            "Iteration: 78\n",
            "Mean loss: 0.2914138285223374\n",
            "Iteration: 79\n",
            "Mean loss: 0.2914133461293768\n",
            "Iteration: 80\n",
            "Mean loss: 0.2914128931575295\n",
            "Iteration: 81\n",
            "Mean loss: 0.29141246717346697\n",
            "Iteration: 82\n",
            "Mean loss: 0.29141206595223734\n",
            "Iteration: 83\n",
            "Mean loss: 0.29141168745888024\n",
            "Iteration: 84\n",
            "Mean loss: 0.29141132983172036\n",
            "Iteration: 85\n",
            "Mean loss: 0.2914109913671781\n",
            "Iteration: 86\n",
            "Mean loss: 0.2914106705059531\n",
            "Iteration: 87\n",
            "Mean loss: 0.2914103658204539\n",
            "Iteration: 88\n",
            "Mean loss: 0.2914100760033536\n",
            "Iteration: 89\n",
            "Mean loss: 0.29140979985716986\n",
            "Iteration: 90\n",
            "Mean loss: 0.2914095362847719\n",
            "Iteration: 91\n",
            "Mean loss: 0.29140928428073104\n",
            "Iteration: 92\n",
            "Mean loss: 0.29140904292343545\n",
            "Iteration: 93\n",
            "Mean loss: 0.2914088113679019\n",
            "Iteration: 94\n",
            "Mean loss: 0.2914085888392182\n",
            "Iteration: 95\n",
            "Mean loss: 0.291408374626562\n",
            "Iteration: 96\n",
            "Mean loss: 0.2914081680777417\n",
            "Iteration: 97\n",
            "Mean loss: 0.2914079685942148\n",
            "Iteration: 98\n",
            "Mean loss: 0.2914077756265387\n",
            "Iteration: 99\n",
            "Mean loss: 0.2914075886702171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[0.08285135, 0.22703369, 0.36334536, 0.2480424 , 0.16580994],\n",
              "         [0.35357484, 0.08972837, 0.16193311, 0.12058107, 0.30308455],\n",
              "         [0.29750997, 0.41604468, 0.13906023, 0.35371698, 0.13902405],\n",
              "         [0.21223707, 0.38759708, 0.15179549, 0.08830987, 0.44578132],\n",
              "         [0.02011602, 0.14726613, 0.20059082, 0.41772329, 0.282435  ]]),\n",
              "  array([[0.38633039, 0.0228394 , 0.37522186, 0.30658345, 0.16427439],\n",
              "         [0.44733439, 0.4425962 , 0.21618013, 0.1905355 , 0.27205532],\n",
              "         [0.12126053, 0.08474766, 0.25209136, 0.21846672, 0.42951039],\n",
              "         [0.35601784, 0.30643256, 0.38142673, 0.2615862 , 0.24127714],\n",
              "         [0.42353995, 0.10521561, 0.4211577 , 0.2567281 , 0.0578499 ]]),\n",
              "  array([[ 0.53569288,  0.1026596 ,  0.17478628,  0.35791055],\n",
              "         [ 0.35950437,  0.3261671 ,  0.23903476,  0.21138561],\n",
              "         [ 0.22078921,  0.03513038,  0.16356797,  0.00683717],\n",
              "         [ 0.48297604,  0.29231821, -0.07378235,  0.33339071],\n",
              "         [ 0.5801992 ,  0.04982692,  0.27550519,  0.31082282]])],\n",
              " [array([[0.79271927, 0.51126984, 0.29164644, 0.68733592, 0.30059246]]),\n",
              "  array([[0.84796886, 0.77873619, 0.61851867, 0.39472149, 0.28614982]]),\n",
              "  array([[0.54549389, 0.050489  , 0.09637377, 0.82127844]])])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making final prediction using trained model\n",
        "pred,A1,H1 = model.forward(X)"
      ],
      "metadata": {
        "id": "q9VE9S-lTQtq"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx2ODeLD9IS9",
        "outputId": "4d2c1cd1-7375-4480-b633-07f34c6c9403"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0.49993306],\n",
            "       [0.09962082],\n",
            "       [0.10043678],\n",
            "       [0.30000933]]), array([[0.5001112 ],\n",
            "       [0.09958727],\n",
            "       [0.10037933],\n",
            "       [0.2999222 ]]), array([[0.49808598],\n",
            "       [0.10013881],\n",
            "       [0.10100829],\n",
            "       [0.30076693]]), array([[0.50007698],\n",
            "       [0.09955193],\n",
            "       [0.10041401],\n",
            "       [0.29995708]]), array([[0.50017945],\n",
            "       [0.09950823],\n",
            "       [0.10037769],\n",
            "       [0.29993464]]), array([[0.49647316],\n",
            "       [0.10059703],\n",
            "       [0.10153825],\n",
            "       [0.30139156]]), array([[0.50162179],\n",
            "       [0.09915813],\n",
            "       [0.09992812],\n",
            "       [0.29929196]]), array([[0.50188967],\n",
            "       [0.09905605],\n",
            "       [0.09985304],\n",
            "       [0.29920124]]), array([[0.50192282],\n",
            "       [0.09903275],\n",
            "       [0.09984414],\n",
            "       [0.2992003 ]]), array([[0.49965965],\n",
            "       [0.09968553],\n",
            "       [0.10050902],\n",
            "       [0.30014579]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Y and Y_hat from lists to numpy arrays\n",
        "Y = np.array(Y)\n",
        "pred = np.array(pred)\n",
        "\n",
        "# Computing the loss using -Y * log(Y_hat)\n",
        "loss = -Y * np.log(pred)\n",
        "\n",
        "# Calculating the mean loss\n",
        "mean_loss = np.mean(loss)\n",
        "\n",
        "print(\"Mean loss:\", mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC1zbfzQ8EwS",
        "outputId": "e7b7062d-ad93-4334-e25c-be61468bd9f1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss: 0.2914074072619058\n"
          ]
        }
      ]
    }
  ]
}